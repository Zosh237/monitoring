Structure du Fichier STATUS.json et Algorithme du Scanner
Ce document détaille le nouveau format du fichier STATUS.json global, qui récapitule toutes les opérations de sauvegarde, ainsi que le fonctionnement affiné du scanner sur le serveur de monitoring.

1. Structure du Fichier STATUS.json (Format Global et Consolidé)
Ce fichier est généré par l'agent distant après l'achèvement de toutes les opérations de sauvegarde et de transfert pour un cycle donné (ex: 13h ou 20h). Il fournit un rapport consolidé pour toutes les bases de données concernées.

Nommage du fichier STATUS.json global :
OPERATION_HORODATAGE_AGENT_ID.json (Ex: 20250612_2000_agent_douala_prod_01.json)

Contenu du fichier STATUS.json (format JSON détaillé) :

{
    "operation_start_time": "2025-06-12T19:00:00Z", // Horodatage global du DÉBUT de l'opération (UTC)
    "operation_timestamp": "2025-06-12T20:00:00Z", // Horodatage global de FIN de l'opération (UTC)
    "agent_id": "agent_douala_prod_01",         // Identifiant de l'agent qui a envoyé le rapport (obligatoire)
    "overall_status": "completed",              // "completed" (si toutes BD rapportées) ou "failed_globally" (si problème majeur)

    "databases": {                              // Dictionnaire des statuts par base de données. La clé est le nom de la BD.
        "DATABASE_NAME_1": {                    // Ex: "compta_db"
            "backup_process": {                // Processus de dump de la BD sur la source
                "status": true,                // true si le dump a réussi
                "backup_process_start_time": "2025-06-12T19:50:00Z", // Heure de début du processus de backup
                "timestamp": "2025-06-12T19:50:00Z", // Timestamp de fin du dump
                "sha256_checksum": "hash_pre_compress_bd1", // Hachage du fichier dumpé AVANT compression/ZTDS
                "size_bytes": 123456789         // Taille du fichier dumpé AVANT compression/ZTDS
            },
            "compress_process": {              // Processus de compression/ZTDS_Resynchable
                "status": true,
                "compress_process_start_time": "2025-06-12T19:50:00Z", // Heure de début du processus de compression
                "timestamp": "2025-06-12T19:55:00Z", // Timestamp de fin de la compression
                "sha256_checksum": "hash_post_compress_bd1", // Hachage du fichier APRES compression/ZTDS (celui qui sera rsync'é)
                "size_bytes": 567890             // Taille du fichier APRES compression/ZTDS
            },
            "transfer_process": {              // Processus rsync vers la zone de staging
                "status": true,                // true si le rsync a réussi
                "transfer_process_start_time": "2025-06-12T19:50:00Z", // Heure de début du processus de transfert
                "timestamp": "2025-06-12T20:00:00Z", // Timestamp de fin de transfert
                "error_message": null          // Message d'erreur si transfer.status est false
            },
            "staged_file_name": "compta_db.sql.gz", // Nom du fichier tel qu'il a été envoyé et est dans la zone de staging
            "logs_summary": "Résumé des logs de l'agent pour cette BD." // Résumé textuel (optionnel)
        },
        "DATABASE_NAME_2": {
            // ... Structure identique pour DATABASE_NAME_2 ...
        }
    }
}

2. Fonctionnement du Scanner (Algorithme Détaillé)
Le scanner exécute une tâche périodique (ex: toutes les 15 minutes) avec le nouvel algorithme suivant :

Détection et Analyse des Fichiers STATUS.json Globaux :

Le scanner parcourt le répertoire /mnt/backups/{année}/{entreprise}/logs_operations/ pour chaque entreprise configurée.

Il identifie les fichiers OPERATION_HORODATAGE_AGENT_ID.json récemment déposés qui correspondent aux cycles de sauvegarde attendus (13h, 20h).

Il lit et valide (via le validation_service) le contenu de ce fichier STATUS.json global.

Traitement Itératif par Base de Données (BD) :

Pour chaque base de données listée dans la section "databases" du STATUS.json global, le scanner :

Récupère le ExpectedBackupJob correspondant dans la base de données de monitoring.

Extrait les statuts détaillés (backup_process, compress_process, transfer_process) rapportés par l'agent.

Contrôle d'Intégrité Côté Serveur (Zone de Staging) :

Si l'agent a signalé un transfer_process.status: true :

Le scanner calcule lui-même le SHA256 et la taille du fichier de sauvegarde (staged_file_name) qui se trouve dans la zone de staging correspondante (/{année}/{entreprise}/{Nom_BD}/staged_file_name.sql.gz).

Il compare ces valeurs calculées par le serveur (server_calculated_staged_hash, server_calculated_staged_size) avec le sha256_checksum (post-compression) et size_bytes (post-compression) fournis par l'agent dans le STATUS.json (section compress_process).

Si non-concordance (hachage ou taille) : Le statut sera TRANSFER_INTEGRITY_FAILED.

Si concordance : Le transfert et l'intégrité du fichier sont validés côté serveur.

Détermination du Statut Final et Action de Promotion :

Le scanner détermine le statut final de la sauvegarde pour chaque BD en fonction de la combinaison des rapports de l'agent et de ses propres vérifications :

MISSING : Si aucun STATUS.json global n'est trouvé pour le cycle attendu, OU si la BD n'est pas mentionnée dans le STATUS.json global, OU si le fichier attendu est absent de la zone de staging.

FAILED : Si l'agent a rapporté un status: false dans backup_process, compress_process ou transfer_process.

TRANSFER_INTEGRITY_FAILED : Si l'agent a rapporté transfer_process.status: true, mais que le hachage ou la taille du fichier stagé calculé par le serveur ne correspond pas à ce que l'agent a rapporté comme post-compression.

HASH_MISMATCH : Si toutes les vérifications précédentes sont positives (agent dit succès, intégrité serveur OK), MAIS le server_calculated_staged_hash est identique au previous_successful_hash_global enregistré en DB pour cette BD (indiquant potentiellement une BD non modifiée).

SUCCESS : Si toutes les vérifications sont positives (agent dit succès, intégrité serveur OK) ET le server_calculated_staged_hash est différent du previous_successful_hash_global.

Action de Promotion Atomique :

Le fichier de sauvegarde dans la zone de staging ne sera copié vers current_version/ UNIQUEMENT si le statut final déterminé par le scanner est SUCCESS.

Pour tous les autres statuts (FAILED, MISSING, TRANSFER_INTEGRITY_FAILED, HASH_MISMATCH), le fichier dans current_version/ n'est pas modifié.

Enregistrement, Notification et Rétention :

Crée une nouvelle BackupEntry dans la base de données pour chaque BD traitée, incluant tous les détails du rapport de l'agent et les résultats des vérifications du scanner.

Met à jour le current_status et last_checked_timestamp de l'ExpectedBackupJob.

Déclenche des alertes (e-mail, etc.) pour les statuts FAILED, MISSING, TRANSFER_INTEGRITY_FAILED, et HASH_MISMATCH.

Une tâche distincte se charge de purger les anciens fichiers STATUS.json du répertoire logs_operations/ et les fichiers de la zone de staging après leur traitement. Le fichier dans current_version/ est maintenu comme la dernière version validée.